{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pizza images: 983\n",
      "Number of non-pizza images: 983\n",
      "Total number of images: 1966\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# define the directories where the imgaes are\n",
    "pizza_directory=\"./pizza/\"\n",
    "not_pizza_directory=\"./not_pizza/\"\n",
    "\n",
    "# get the images from the directories\n",
    "not_pizza_files=[[0, not_pizza_directory, i] for i in os.listdir(not_pizza_directory)]\n",
    "pizza_files=[[1, pizza_directory, i] for i in os.listdir(pizza_directory)]\n",
    "\n",
    "print(\"Number of pizza images:\",len(pizza_files))\n",
    "print(\"Number of non-pizza images:\",len(not_pizza_files))\n",
    "\n",
    "# combine the image sets\n",
    "all_files = not_pizza_files + pizza_files\n",
    "\n",
    "print(\"Total number of images:\", len(all_files))\n",
    "\n",
    "# each element in all_files is of the format [is_pizza: boolean, directory: string, filename: string]\n",
    "# in other words, for each `img` in `all_files`:\n",
    "#    - img[0] = 0 if not pizza, 1 if pizza\n",
    "#    - img[1] = directory where the image is\n",
    "#    - img[2] = file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "standardSize = (128,128)\n",
    "resizedImages = list()\n",
    "isPizzaArray = list()\n",
    "\n",
    "# structure is:\n",
    "# resizedImages[i] = 2-D numpy array of pixels, [128][128][3]\n",
    "\n",
    "\n",
    "PATH = os.path.abspath(os.getcwd())\n",
    "if (not os.path.exists(f'{PATH}/resizedImages')):\n",
    "    os.mkdir('resizedImages')\n",
    "\n",
    "for i, image in enumerate(all_files):\n",
    "    imgData = Image.open(image[1] + image[2])\n",
    "    imgData = imgData.resize(standardSize)\n",
    "    imgData.save(f'{PATH}/resizedImages/{i}.jpg')\n",
    "    # storing images\n",
    "    resizedImages.append(np.array(imgData))\n",
    "    isPizzaArray.append(image[0])\n",
    "\n",
    "X = np.array(resizedImages)\n",
    "y = np.array(isPizzaArray)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "# ! Takes about 30 seconds...\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Second Model, using an SVM.\n",
    "To determine best svm kernel we iterated through a random subset of our data and computed the score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking which kernel works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# thing=X_trai[0].reshape(1,X_train[0].size)\n",
    "# thing.shape\n",
    "\n",
    "imgSize = standardSize[0] * standardSize[1] * 3\n",
    "\n",
    "X_trainSVM=np.array(X_train.reshape((X_train.shape[0], imgSize)),dtype=np.uint8)\n",
    "X_testSVM=np.array(X_test.reshape((X_test.shape[0], imgSize)),dtype=np.uint8)\n",
    "\n",
    "for i in [\"linear\",\"rbf\",\"poly\",\"sigmoid\"]:\n",
    "    SVM_cl=SVC(kernel=i)\n",
    "    SVM_cl.fit(X_trainSVM,y_train)\n",
    "    print(\"Mean accuracy of kernel {} {}\".format(i,SVM_cl.score(X_testSVM,y_test)))\n",
    "    #Best appears to be sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implement SVM calc, with Naive Bayes\n",
    "We could not append the svm score of each image to the obseravtion data of the images being fed to the neural net. Because the neural net uses convolution, we could not add more dimensions, or replace one of the tensors with the svm score without causing erronious bias. So instead, we inserted the SVM classification and neural net classification into a Categorical Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "315/315 [==============================] - 11s 28ms/step - loss: 0.9471 - accuracy: 0.5560\n",
      "Epoch 2/3\n",
      "315/315 [==============================] - 9s 30ms/step - loss: 0.5664 - accuracy: 0.7271\n",
      "Epoch 3/3\n",
      "315/315 [==============================] - 9s 29ms/step - loss: 0.3823 - accuracy: 0.8365\n",
      "50/50 [==============================] - 3s 54ms/step\n",
      "13/13 [==============================] - 1s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(1)\n",
    "\n",
    "imgSize = standardSize[0] * standardSize[1] * 3\n",
    "\n",
    "\"Preparing data\"\n",
    "\"Create and Run NN\"\n",
    "model = Sequential() # Initialising the ANN\n",
    "imgShape = (standardSize[0], standardSize[1], 3)\n",
    "model.add(Conv2D(7, 3, activation = 'tanh',input_shape=imgShape))\n",
    "model.add(Conv2D(3, 2, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation=\"sigmoid\")) #Here is the difference. Each pixel will push the image above or below the SVM constraints.\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy',metrics=[\"accuracy\"])\n",
    "numEpoches = 3\n",
    "model.fit(X_train, y_train, batch_size = 5, epochs = 3, verbose = 1)\n",
    "NN_SVM_pred_train=[[np.round(i)] for i in model.predict(X_train)]\n",
    "NN_SVM_pred_test=[[np.round(i)] for i in model.predict(X_test)]\n",
    "\n",
    "\"Create and Run SVM\"\n",
    "X_trai_SVM=np.array(X_train.reshape((X_train.shape[0], imgSize)),dtype=np.uint8)\n",
    "X_tes_SVM=np.array(X_test.reshape((X_test.shape[0], imgSize)),dtype=np.uint8)\n",
    "SVM_cl=SVC(kernel=\"sigmoid\")\n",
    "SVM_cl.fit(X_trai_SVM,y_train)\n",
    "for i,ii in enumerate(SVM_cl.predict(X_tes_SVM)):\n",
    "    NN_SVM_pred_test[i].append(ii)\n",
    "for i,ii in enumerate(SVM_cl.predict(X_trai_SVM)):\n",
    "    NN_SVM_pred_train[i].append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61       197\n",
      "           1       0.60      0.53      0.56       197\n",
      "\n",
      "    accuracy                           0.59       394\n",
      "   macro avg       0.59      0.59      0.58       394\n",
      "weighted avg       0.59      0.59      0.58       394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:845: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:845: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"Create and Run Naive\"\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import classification_report\n",
    "CNB_obj=CategoricalNB()                     #initialized object\n",
    "CNB_obj.fit(X=NN_SVM_pred_train,y=y_train)\n",
    "print(classification_report(y_test,CNB_obj.predict(NN_SVM_pred_test))) #classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
